# Whisperãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè£…å®Œå…¨ã‚¬ã‚¤ãƒ‰ï¼šCPUã‚ªãƒ³ãƒªãƒ¼ã§å®Ÿç¾ã™ã‚‹é«˜ç²¾åº¦éŸ³å£°èªè­˜

![Badge](https://img.shields.io/badge/AI%E9%96%8B%E7%99%BA-Whisper%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB-orange.svg)

## å®Ÿç¾ã§ãã‚‹ã“ã¨

<div class="grid cards" markdown>

-   :material-shield-lock: **å®Œå…¨ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆå‡¦ç†**
    
    ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Whisperã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œã€æ©Ÿå¯†æƒ…å ±ã®æ¼æ´©ã‚¼ãƒ­

-   :material-cpu-64-bit: **CPUå°‚ç”¨é«˜é€ŸåŒ–**
    
    faster-whisperã§GPUä¸è¦ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚ˆã‚Š4å€é«˜é€Ÿãªå‡¦ç†

-   :material-microsoft-windows: **Windowsçµ±åˆ**
    
    Win+HéŸ³å£°å…¥åŠ›ã¨ã®é€£æºã§æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«è‡ªç„¶çµ±åˆ

-   :material-speedometer: **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†**
    
    2025å¹´æœ€æ–°ã®large-v3-turboã§3å€é«˜é€Ÿã€å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã®å¿œç­”é€Ÿåº¦

</div>

## ğŸ“– Overview

2025å¹´ã€OpenAI Whisperã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè£…ã¯é©å‘½çš„ãªé€²åŒ–ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚å¾“æ¥GPUãŒå¿…é ˆã ã£ãŸé«˜ç²¾åº¦éŸ³å£°èªè­˜ãŒã€CPUã‚ªãƒ³ãƒªãƒ¼ã§å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã—ã¾ã—ãŸã€‚

ç‰¹ã«æ³¨ç›®ã™ã¹ãã¯ã€Œfaster-whisperã€ã¨ã€Œlarge-v3-turboã€ãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã§ã™ã€‚ã“ã‚Œã‚‰ã®æŠ€è¡“ã«ã‚ˆã‚Šã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å®Œå…¨ã«ä¿è­·ã—ãªãŒã‚‰ã€å•†ç”¨ãƒ¬ãƒ™ãƒ«ã®éŸ³å£°èªè­˜ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿç¾ã§ãã¾ã™ã€‚

æœ¬è¨˜äº‹ã§ã¯ã€Whisperã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§CPUå‡¦ç†ã«ã‚ˆã‚Šå®Ÿè£…ã—ã€Windowsæ¨™æº–ã®éŸ³å£°å…¥åŠ›æ©Ÿèƒ½ã¨é€£æºã•ã›ã‚‹å®Œå…¨ãªæ‰‹é †ã‚’è§£èª¬ã—ã¾ã™ã€‚

## ğŸ”§ Implementation

### Step 1: ç’°å¢ƒæ§‹ç¯‰

#### Pythonç’°å¢ƒã®æº–å‚™

```bash
# Pythonä»®æƒ³ç’°å¢ƒã®ä½œæˆ
python -m venv whisper-local
whisper-local\Scripts\activate.bat  # Windows

# å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install faster-whisper
pip install numpy==1.26.4  # äº’æ›æ€§ç¢ºä¿
pip install pyaudio
pip install keyboard  # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒ•ãƒƒã‚¯ç”¨
pip install pywin32   # Windows APIç”¨
```

#### FFmpegã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Chocolateyã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
choco install ffmpeg

# ã¾ãŸã¯æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# 1. https://github.com/BtbN/FFmpeg-Builds/releases ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# 2. C:\ffmpeg ã«å±•é–‹
# 3. ç’°å¢ƒå¤‰æ•°Pathã« C:\ffmpeg\bin ã‚’è¿½åŠ 
```

### Step 2: Whisperãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè£…ã®åŸºæœ¬

#### åŸºæœ¬çš„ãªéŸ³å£°èªè­˜

```python
# whisper_basic.py
from faster_whisper import WhisperModel
import warnings
warnings.filterwarnings("ignore")

class LocalWhisper:
    def __init__(self, model_size="base", device="cpu", compute_type="int8"):
        """
        Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        
        Args:
            model_size: "tiny", "base", "small", "medium", "large-v3", "large-v3-turbo"
            device: "cpu" (GPUä¸ä½¿ç”¨)
            compute_type: "int8" (CPUæœ€é©åŒ–)
        """
        print(f"Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_size}")
        self.model = WhisperModel(
            model_size, 
            device=device, 
            compute_type=compute_type,
            cpu_threads=4  # CPUã‚³ã‚¢æ•°ã«å¿œã˜ã¦èª¿æ•´
        )
        print("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    
    def transcribe_file(self, audio_path, language="ja"):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—"""
        try:
            segments, info = self.model.transcribe(
                audio_path,
                language=language,
                beam_size=1,  # CPUå‡¦ç†æ™‚ã¯1ãŒæœ€é©
                temperature=0.0,
                vad_filter=True,  # ç„¡éŸ³éƒ¨åˆ†é™¤å»
                vad_parameters=dict(
                    min_silence_duration_ms=1000,
                    speech_pad_ms=400
                )
            )
            
            # çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦çµåˆ
            text = ""
            for segment in segments:
                text += segment.text
            
            return text.strip()
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    whisper = LocalWhisper(model_size="base")
    result = whisper.transcribe_file("test_audio.wav")
    print(f"èªè­˜çµæœ: {result}")
```

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜

```python
# whisper_realtime.py
import pyaudio
import wave
import threading
import queue
import time
from faster_whisper import WhisperModel

class RealtimeWhisper:
    def __init__(self, model_size="base"):
        # éŸ³å£°è¨­å®š
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.RECORD_SECONDS = 3  # 3ç§’ãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†
        
        # Whisperãƒ¢ãƒ‡ãƒ«
        self.model = WhisperModel(model_size, device="cpu", compute_type="int8")
        
        # PyAudioåˆæœŸåŒ–
        self.audio = pyaudio.PyAudio()
        
        # ã‚­ãƒ¥ãƒ¼ã¨ãƒ•ãƒ©ã‚°
        self.audio_queue = queue.Queue()
        self.is_recording = False
        
    def record_audio(self):
        """éŸ³å£°éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰"""
        stream = self.audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK
        )
        
        print("éŒ²éŸ³é–‹å§‹... (Ctrl+Cã§åœæ­¢)")
        
        while self.is_recording:
            frames = []
            for _ in range(int(self.RATE / self.CHUNK * self.RECORD_SECONDS)):
                if not self.is_recording:
                    break
                data = stream.read(self.CHUNK)
                frames.append(data)
            
            if frames:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                audio_data = b''.join(frames)
                self.audio_queue.put(audio_data)
        
        stream.stop_stream()
        stream.close()
    
    def process_audio(self):
        """éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        while self.is_recording:
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                audio_data = self.audio_queue.get(timeout=1)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                temp_file = "temp_audio.wav"
                with wave.open(temp_file, 'wb') as wf:
                    wf.setnchannels(self.CHANNELS)
                    wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
                    wf.setframerate(self.RATE)
                    wf.writeframes(audio_data)
                
                # Whisperã§èªè­˜
                segments, _ = self.model.transcribe(
                    temp_file,
                    language="ja",
                    beam_size=1,
                    vad_filter=True
                )
                
                # çµæœå‡ºåŠ›
                text = ""
                for segment in segments:
                    text += segment.text
                
                if text.strip():
                    print(f"èªè­˜çµæœ: {text.strip()}")
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def start(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜é–‹å§‹"""
        self.is_recording = True
        
        # éŒ²éŸ³ã¨å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        record_thread = threading.Thread(target=self.record_audio)
        process_thread = threading.Thread(target=self.process_audio)
        
        record_thread.start()
        process_thread.start()
        
        try:
            record_thread.join()
            process_thread.join()
        except KeyboardInterrupt:
            print("\nåœæ­¢ä¸­...")
            self.is_recording = False
        
    def __del__(self):
        if hasattr(self, 'audio'):
            self.audio.terminate()

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    whisper_rt = RealtimeWhisper(model_size="base")
    whisper_rt.start()
```

### Step 3: WindowséŸ³å£°å…¥åŠ›çµ±åˆ

#### Win+Hãƒ•ãƒƒã‚¯å®Ÿè£…

```python
# windows_voice_integration.py
import keyboard
import time
import subprocess
import win32clipboard
import win32con
from faster_whisper import WhisperModel
import pyaudio
import wave
import threading

class WindowsVoiceIntegration:
    def __init__(self, model_size="base"):
        self.whisper = WhisperModel(model_size, device="cpu", compute_type="int8")
        self.is_recording = False
        self.audio_config = {
            'chunk': 1024,
            'format': pyaudio.paInt16,
            'channels': 1,
            'rate': 16000
        }
        self.audio = pyaudio.PyAudio()
        
        print("WindowséŸ³å£°å…¥åŠ›çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  Ctrl+Shift+V: ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°å…¥åŠ›é–‹å§‹")
        print("  Win+H: æ¨™æº–éŸ³å£°å…¥åŠ›ï¼ˆç½®ãæ›ãˆï¼‰")
    
    def record_and_transcribe(self, duration=5):
        """éŸ³å£°éŒ²éŸ³ã¨æ–‡å­—èµ·ã“ã—"""
        print("éŒ²éŸ³é–‹å§‹...")
        
        stream = self.audio.open(
            format=self.audio_config['format'],
            channels=self.audio_config['channels'],
            rate=self.audio_config['rate'],
            input=True,
            frames_per_buffer=self.audio_config['chunk']
        )
        
        frames = []
        for _ in range(int(self.audio_config['rate'] / self.audio_config['chunk'] * duration)):
            data = stream.read(self.audio_config['chunk'])
            frames.append(data)
        
        stream.stop_stream()
        stream.close()
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        temp_file = "voice_input.wav"
        with wave.open(temp_file, 'wb') as wf:
            wf.setnchannels(self.audio_config['channels'])
            wf.setsampwidth(self.audio.get_sample_size(self.audio_config['format']))
            wf.setframerate(self.audio_config['rate'])
            wf.writeframes(b''.join(frames))
        
        print("éŸ³å£°èªè­˜ä¸­...")
        
        # Whisperã§æ–‡å­—èµ·ã“ã—
        segments, _ = self.whisper.transcribe(
            temp_file,
            language="ja",
            beam_size=1,
            vad_filter=True,
            temperature=0.0
        )
        
        text = ""
        for segment in segments:
            text += segment.text
        
        return text.strip()
    
    def set_clipboard_text(self, text):
        """ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š"""
        win32clipboard.OpenClipboard()
        win32clipboard.EmptyClipboard()
        win32clipboard.SetClipboardText(text, win32con.CF_UNICODETEXT)
        win32clipboard.CloseClipboard()
    
    def simulate_paste(self):
        """Ctrl+Vã§ãƒšãƒ¼ã‚¹ãƒˆå®Ÿè¡Œ"""
        time.sleep(0.1)
        keyboard.send('ctrl+v')
    
    def custom_voice_input(self):
        """ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°å…¥åŠ›å‡¦ç†"""
        try:
            text = self.record_and_transcribe(duration=5)
            if text:
                print(f"èªè­˜çµæœ: {text}")
                self.set_clipboard_text(text)
                self.simulate_paste()
                print("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›å®Œäº†")
            else:
                print("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    def windows_h_hook(self):
        """Win+Hç½®ãæ›ãˆå‡¦ç†"""
        # æ¨™æº–ã®Win+Hã‚’ç„¡åŠ¹åŒ–ã—ã€ã‚«ã‚¹ã‚¿ãƒ å‡¦ç†ã‚’å®Ÿè¡Œ
        print("Win+H ãŒæŠ¼ã•ã‚Œã¾ã—ãŸ - ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹")
        self.custom_voice_input()
    
    def start_monitoring(self):
        """ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–é–‹å§‹"""
        print("ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–é–‹å§‹...")
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ›ãƒƒãƒˆã‚­ãƒ¼: Ctrl+Shift+V
        keyboard.add_hotkey('ctrl+shift+v', self.custom_voice_input)
        
        # Win+Hç½®ãæ›ãˆï¼ˆæ³¨æ„: ç®¡ç†è€…æ¨©é™ãŒå¿…è¦ï¼‰
        try:
            keyboard.add_hotkey('win+h', self.windows_h_hook)
            print("Win+H ãƒ•ãƒƒã‚¯è¨­å®šå®Œäº†")
        except:
            print("Win+H ãƒ•ãƒƒã‚¯è¨­å®šå¤±æ•—ï¼ˆç®¡ç†è€…æ¨©é™ãŒå¿…è¦ï¼‰")
            print("ä»£æ›¿: Ctrl+Shift+V ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        
        print("ç›£è¦–ä¸­... (Ctrl+C ã§çµ‚äº†)")
        keyboard.wait()

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    try:
        integration = WindowsVoiceIntegration(model_size="base")
        integration.start_monitoring()
    except KeyboardInterrupt:
        print("\nã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")
```

### Step 4: æœ€é©åŒ–ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´

#### CPUæœ€é©åŒ–è¨­å®š

```python
# performance_optimizer.py
import os
import psutil
from faster_whisper import WhisperModel

class WhisperOptimizer:
    def __init__(self):
        self.cpu_count = psutil.cpu_count()
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        
    def get_optimal_settings(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã«æœ€é©ãªè¨­å®šã‚’ææ¡ˆ"""
        
        # CPUã‚³ã‚¢æ•°ã«åŸºã¥ãã‚¹ãƒ¬ãƒƒãƒ‰æ•°
        if self.cpu_count >= 8:
            cpu_threads = 6
            model_size = "medium"
        elif self.cpu_count >= 4:
            cpu_threads = 4
            model_size = "base"
        else:
            cpu_threads = 2
            model_size = "tiny"
        
        # ãƒ¡ãƒ¢ãƒªã«åŸºã¥ããƒ¢ãƒ‡ãƒ«é¸æŠ
        if self.memory_gb < 4:
            model_size = "tiny"
            compute_type = "int8"
        elif self.memory_gb < 8:
            model_size = "base"
            compute_type = "int8"
        else:
            compute_type = "float16"
        
        return {
            'model_size': model_size,
            'cpu_threads': cpu_threads,
            'compute_type': compute_type,
            'beam_size': 1,  # CPUå‡¦ç†æ™‚ã¯1ãŒæœ€é©
            'batch_size': 1
        }
    
    def create_optimized_model(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸWhisperãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        settings = self.get_optimal_settings()
        
        print(f"ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
        print(f"  CPU: {self.cpu_count}ã‚³ã‚¢")
        print(f"  ãƒ¡ãƒ¢ãƒª: {self.memory_gb:.1f}GB")
        print(f"æ¨å¥¨è¨­å®š:")
        print(f"  ãƒ¢ãƒ‡ãƒ«: {settings['model_size']}")
        print(f"  ã‚¹ãƒ¬ãƒƒãƒ‰: {settings['cpu_threads']}")
        print(f"  è¨ˆç®—ã‚¿ã‚¤ãƒ—: {settings['compute_type']}")
        
        return WhisperModel(
            settings['model_size'],
            device="cpu",
            compute_type=settings['compute_type'],
            cpu_threads=settings['cpu_threads']
        ), settings

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
def benchmark_models():
    """å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    import time
    
    models = ["tiny", "base", "small"]
    test_file = "test_audio.wav"  # ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
    
    for model_name in models:
        print(f"\n{model_name}ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆä¸­...")
        
        start_time = time.time()
        model = WhisperModel(model_name, device="cpu", compute_type="int8")
        load_time = time.time() - start_time
        
        start_time = time.time()
        segments, _ = model.transcribe(test_file, beam_size=1)
        transcribe_time = time.time() - start_time
        
        print(f"  èª­ã¿è¾¼ã¿æ™‚é–“: {load_time:.2f}ç§’")
        print(f"  èªè­˜æ™‚é–“: {transcribe_time:.2f}ç§’")

if __name__ == "__main__":
    optimizer = WhisperOptimizer()
    model, settings = optimizer.create_optimized_model()
    print("\næœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")
```

## ğŸ’¡ Best Practices

### 1. ãƒ¢ãƒ‡ãƒ«é¸æŠã®æŒ‡é‡

**tiny (39MB)**:
- ç”¨é€”: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã€ä½ã‚¹ãƒšãƒƒã‚¯PC
- ç²¾åº¦: åŸºæœ¬ãƒ¬ãƒ™ãƒ«ï¼ˆä¼šè©±ã®å¤§ã¾ã‹ãªå†…å®¹æŠŠæ¡ï¼‰
- é€Ÿåº¦: æœ€é«˜é€Ÿï¼ˆå®Ÿæ™‚é–“ã®0.1å€ï¼‰

**base (74MB)**:
- ç”¨é€”: ä¸€èˆ¬çš„ãªéŸ³å£°èªè­˜ã€ãƒãƒ©ãƒ³ã‚¹é‡è¦–
- ç²¾åº¦: å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼ˆæ—¥å¸¸ä¼šè©±ã€ä¼šè­°éŒ²éŸ³ï¼‰
- é€Ÿåº¦: é«˜é€Ÿï¼ˆå®Ÿæ™‚é–“ã®0.16å€ï¼‰

**large-v3-turbo (809MB)**:
- ç”¨é€”: é«˜ç²¾åº¦ãŒå¿…è¦ãªæ–‡å­—èµ·ã“ã—
- ç²¾åº¦: æœ€é«˜ãƒ¬ãƒ™ãƒ«ï¼ˆ94%ã®æ—¥æœ¬èªèªè­˜ç²¾åº¦ï¼‰
- é€Ÿåº¦: mediumç›¸å½“ã®é€Ÿåº¦ã§largeç›¸å½“ã®ç²¾åº¦

### 2. CPUæœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

```python
# CPUæœ€é©åŒ–ã®å®Ÿè£…ä¾‹
import os

# OpenMPã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’åˆ¶é™ï¼ˆCPUã‚³ã‚¢æ•°ã®75%ï¼‰
os.environ["OMP_NUM_THREADS"] = str(max(1, psutil.cpu_count() * 3 // 4))

# NumPyã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•°åˆ¶é™
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

# faster-whisperã®æœ€é©è¨­å®š
model = WhisperModel(
    "base",
    device="cpu",
    compute_type="int8",  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
    cpu_threads=4,       # CPUã‚³ã‚¢æ•°ã«å¿œã˜ã¦èª¿æ•´
    num_workers=1        # ä¸¦åˆ—å‡¦ç†æ•°
)
```

### 3. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›

```python
# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã®è¨­å®š
def create_memory_efficient_model():
    return WhisperModel(
        "base",
        device="cpu",
        compute_type="int8",      # FP16â†’INT8ã§å¤§å¹…å‰Šæ¸›
        download_root="./models", # ãƒ¢ãƒ‡ãƒ«ä¿å­˜å ´æ‰€æŒ‡å®š
        local_files_only=False
    )

# ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ˜ç¤ºçš„å®Ÿè¡Œ
import gc
gc.collect()
```

## ğŸš€ Advanced Usage

### ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ–ãƒ«éŸ³å£°ã‚³ãƒãƒ³ãƒ‰

```python
# voice_commands.py
import re
from faster_whisper import WhisperModel

class VoiceCommandProcessor:
    def __init__(self):
        self.model = WhisperModel("base", device="cpu", compute_type="int8")
        self.commands = {
            r"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã": self.open_file,
            r"æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«": self.new_file,
            r"ä¿å­˜": self.save_file,
            r"ã‚³ãƒ”ãƒ¼": self.copy_text,
            r"ãƒšãƒ¼ã‚¹ãƒˆ": self.paste_text,
            r"æ¤œç´¢.*": self.search_text
        }
    
    def process_command(self, audio_file):
        """éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""
        # éŸ³å£°èªè­˜
        segments, _ = self.model.transcribe(audio_file, language="ja")
        text = "".join([segment.text for segment in segments]).strip()
        
        print(f"èªè­˜ã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰: {text}")
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for pattern, action in self.commands.items():
            if re.match(pattern, text):
                action(text)
                return True
        
        # ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        self.input_text(text)
        return False
    
    def open_file(self, text):
        print("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¾ã™")
        keyboard.send('ctrl+o')
    
    def new_file(self, text):
        print("æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™")
        keyboard.send('ctrl+n')
    
    def save_file(self, text):
        print("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã™")
        keyboard.send('ctrl+s')
    
    def copy_text(self, text):
        print("ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã™")
        keyboard.send('ctrl+c')
    
    def paste_text(self, text):
        print("ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒšãƒ¼ã‚¹ãƒˆã—ã¾ã™")
        keyboard.send('ctrl+v')
    
    def search_text(self, text):
        # "æ¤œç´¢ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keyword = text.replace("æ¤œç´¢", "").strip()
        print(f"'{keyword}'ã‚’æ¤œç´¢ã—ã¾ã™")
        keyboard.send('ctrl+f')
        time.sleep(0.1)
        keyboard.write(keyword)
    
    def input_text(self, text):
        """é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›"""
        print(f"ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›: {text}")
        keyboard.write(text)
```

### ãƒãƒƒãƒå‡¦ç†ã¨è‡ªå‹•åŒ–

```python
# batch_processor.py
import os
import glob
from concurrent.futures import ThreadPoolExecutor
from faster_whisper import WhisperModel

class BatchWhisperProcessor:
    def __init__(self, model_size="base", max_workers=2):
        self.model = WhisperModel(model_size, device="cpu", compute_type="int8")
        self.max_workers = max_workers
    
    def process_file(self, audio_file):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        try:
            print(f"å‡¦ç†ä¸­: {audio_file}")
            segments, info = self.model.transcribe(
                audio_file,
                language="ja",
                beam_size=1,
                vad_filter=True
            )
            
            # çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            text = "".join([segment.text for segment in segments])
            output_file = os.path.splitext(audio_file)[0] + "_transcript.txt"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(text)
            
            print(f"å®Œäº†: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ ({audio_file}): {e}")
            return None
    
    def process_directory(self, directory, pattern="*.wav"):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†"""
        audio_files = glob.glob(os.path.join(directory, pattern))
        print(f"å‡¦ç†å¯¾è±¡: {len(audio_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(self.process_file, audio_files))
        
        successful = [r for r in results if r is not None]
        print(f"å‡¦ç†å®Œäº†: {len(successful)}/{len(audio_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        return successful

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    processor = BatchWhisperProcessor(model_size="base", max_workers=2)
    processor.process_directory("./audio_files", "*.wav")
```

## âš ï¸ Troubleshooting

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

**å•é¡Œ1: NumPyäº’æ›æ€§ã‚¨ãƒ©ãƒ¼**
```bash
# è§£æ±ºç­–
pip uninstall numpy
pip install numpy==1.26.4
```

**å•é¡Œ2: FFmpeg not found**
```bash
# Windowsç’°å¢ƒã§ã®è§£æ±º
# 1. FFmpegãƒã‚¤ãƒŠãƒªã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# 2. ç’°å¢ƒå¤‰æ•°Pathã«è¿½åŠ 
# 3. ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç¢ºèª
ffmpeg -version
```

**å•é¡Œ3: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼**
```python
# è»½é‡ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´
model = WhisperModel("tiny", device="cpu", compute_type="int8")

# ã¾ãŸã¯å‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’èª¿æ•´
segments, _ = model.transcribe(
    audio_file,
    beam_size=1,  # ãƒ“ãƒ¼ãƒ ã‚µã‚¤ã‚ºã‚’1ã«
    best_of=1     # ãƒ™ã‚¹ãƒˆå€™è£œæ•°ã‚’1ã«
)
```

**å•é¡Œ4: èªè­˜ç²¾åº¦ã®ä½ä¸‹**
```python
# VADãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®èª¿æ•´
segments, _ = model.transcribe(
    audio_file,
    vad_filter=True,
    vad_parameters=dict(
        min_silence_duration_ms=500,  # ç„¡éŸ³åˆ¤å®šã‚’çŸ­ã
        speech_pad_ms=200            # éŸ³å£°ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª¿æ•´
    )
)
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„

```python
# performance_tips.py

# 1. ãƒ—ãƒ­ã‚»ã‚¹å„ªå…ˆåº¦ã®è¨­å®š
import psutil
import os

process = psutil.Process(os.getpid())
process.nice(psutil.HIGH_PRIORITY_CLASS)  # Windows

# 2. CPUã‚¢ãƒ•ã‚£ãƒ‹ãƒ†ã‚£ã®è¨­å®š
cpu_count = psutil.cpu_count()
if cpu_count > 4:
    # ç‰©ç†ã‚³ã‚¢ã®ã¿ä½¿ç”¨ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é¿ã‘ã‚‹ï¼‰
    process.cpu_affinity(list(range(0, cpu_count//2)))

# 3. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
def monitor_memory_usage():
    memory = psutil.virtual_memory()
    print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory.percent}%")
    if memory.percent > 85:
        print("è­¦å‘Š: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã™ãã¾ã™")
```

## ğŸ”— Related Articles

- [éŸ³å£°å…¥åŠ›ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é©å‘½2025](./voice-input-programming-2025.md)
- [Claude Codeã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®å¯èƒ½æ€§](./claude-code-project-management.md)
- [AIé–‹ç™ºç’°å¢ƒã®æ§‹ç¯‰ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](./ai-development-environment.md)

---